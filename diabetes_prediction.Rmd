---
title: "Diabetes Prediction Regression Analysis"
author: "Manas Reddy"
date: "`r Sys.Date()`"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```

## Introduction

This document presents a regression analysis workflow to predict `Fasting_Blood_Glucose` using the provided diabetes dataset. The process includes data loading, exploratory data analysis, preprocessing, and training a LightGBM regression model.

## Load Libraries

```{r load_libraries}
library(readr)
library(dplyr)
library(ggplot2)
library(reshape2)
library(caret) # For train/test split
library(lightgbm) # For LightGBM model
library(corrplot) # For correlation plot
```

## Load Data

```{r load_data}
# Load the dataset
df <- read_csv('diabetes_dataset.csv')
```

## Initial Data Inspection

```{r initial_inspection}
# Check for missing values
cat("Missing values per column:\n")
print(colSums(is.na(df)))

# Get information about the data frame
cat("\nData frame structure:\n")
print(str(df))
```

## Exploratory Data Analysis: Distributions

Histograms are plotted for selected numerical features. Categorical features are visualized later using pie charts.

```{r histograms, fig.width=10, fig.height=8}
# Plot histograms
hist_cols <- c('Age', 'Dietary_Intake_Calories', 'Fasting_Blood_Glucose', 'BMI')
par(mfrow=c(2, 2)) 
for (col in hist_cols) {
  hist(df[[col]], main = paste(col, 'Distribution'), xlab = col, probability = TRUE, col = 'lightblue', border = 'black')
  lines(density(df[[col]], na.rm = TRUE), col = 'blue', lwd = 2)
}
par(mfrow=c(1, 1))
```

Pie charts are used to visualize the distribution of categorical variables.

```{r pie_charts, fig.width=12, fig.height=8}
# Plot pie charts
pie_cols <- c('Alcohol_Consumption', 'Sex', 'Ethnicity', 'Smoking_Status', 'Physical_Activity_Level', 'Previous_Gestational_Diabetes')
par(mfrow=c(2, 3)) 
for (col in pie_cols) {
  counts <- table(df[[col]])
  pie(counts, main = paste('Pie Plot of', col), col = rainbow(length(counts)))
}
par(mfrow=c(1, 1)) 
```

## Data Preprocessing

Handling missing values and converting categorical columns to factors.

```{r preprocessing}
# Fill missing values in 'Alcohol_Consumption'
df$Alcohol_Consumption[is.na(df$Alcohol_Consumption)] <- 'Not Reported'
cat("Missing values after filling Alcohol_Consumption:\n")
print(colSums(is.na(df)))

# Factor Conversion
factor_cols <- c('Sex', 'Smoking_Status', 'Ethnicity', 'Alcohol_Consumption', 'Physical_Activity_Level', 'Previous_Gestational_Diabetes')
for (col in factor_cols) {
  df[[col]] <- as.factor(df[[col]])
}

cat("\nData frame structure after factor conversion:\n")
print(str(df))
```

## Exploratory Data Analysis: Boxplots

Boxplots help visualize the distribution and potential outliers for numerical features, and also distributions of a numerical feature across categories (when used with a factor on the x-axis, although here we plot single distributions).

```{r boxplots, fig.width=10, fig.height=8}
# Plot boxplots
boxplot_cols <- c('Age', 'Dietary_Intake_Calories', 'Fasting_Blood_Glucose', 'BMI', 'Alcohol_Consumption', 'Previous_Gestational_Diabetes')
par(mfrow=c(2, 3)) # Arrange plots in a 2x3 grid
for (col in boxplot_cols) {
   boxplot(df[[col]], main = paste('Box Plot of', col), ylab = col)
}
par(mfrow=c(1, 1))
```

## Correlation Analysis

Visualizing the correlation matrix of numerical features.

```{r correlation_heatmap, fig.width=12, fig.height=10}
# Select only numeric columns for correlation
numeric_df <- df %>% select_if(is.numeric)
corr_matrix <- cor(numeric_df, use = "complete.obs") # Handle potential NAs in numeric columns for correlation
corrplot(corr_matrix, method = "color", type = "full", order = "hclust",
         tl.col = "black", tl.srt = 45, addCoef.col = "black", number.cex = 0.7,
         main = "Correlation Heatmap")
```

## Data Splitting

Splitting the data into training and testing sets (80/20 split).

```{r data_split}
# Drop the index column (read as '...1') and 'Fasting_Blood_Glucose' from features
X <- df %>% select(-`...1`, -Fasting_Blood_Glucose)
y <- df$Fasting_Blood_Glucose

# Split data into training and testing sets
set.seed(42) # for reproducibility
train_indices <- createDataPartition(y, p = 0.8, list = FALSE)
X_train <- X[train_indices, ]
X_test <- X[-train_indices, ]
y_train <- y[train_indices]
y_test <- y[-train_indices]

cat("Number of training samples:", nrow(X_train), "\n")
cat("Number of training labels:", length(y_train), "\n")
cat("Number of testing samples:", nrow(X_test), "\n")
cat("Number of testing labels:", length(y_test), "\n")
```

## LightGBM Model Training

Train a LightGBM regressor model. Categorical features are explicitly identified.

```{r lightgbm_training}
# Train LightGBM regression model
categorical_features_names <- c('Sex', 'Ethnicity', 'Physical_Activity_Level', 'Alcohol_Consumption', 'Smoking_Status', 'Previous_Gestational_Diabetes')

# Get 0-based indices of these columns in the X_train data frame
current_X_train_cols <- colnames(X_train)
categorical_feature_indices <- which(current_X_train_cols %in% categorical_features_names) - 1 

dtrain <- lgb.Dataset(data = as.matrix(X_train), label = y_train,
                      categorical_feature = categorical_feature_indices)

# Define parameters
params <- list(objective = "regression", metric = "l2")

model <- lgb.train(params = params,
                   data = dtrain,
                   nrounds = 100 
                   )
```

## Model Evaluation

Evaluate the trained model on the test set using R-squared.

```{r model_evaluation}
# Evaluate the model 
predictions <- predict(model, as.matrix(X_test))

# Calculate R-squared
ssr <- sum((y_test - predictions)^2)
sst <- sum((y_test - mean(y_test))^2)
r_squared <- 1 - (ssr / sst)

cat("R-squared score on the test set:", r_squared, "\n")
```

## Model Insights

Let's examine the trained model by looking at feature importance and comparing actual vs. predicted values.

### Feature Importance

Understanding which features the model considered most important for the prediction task.

```{r feature_importance, fig.width=10, fig.height=6}
# Calculate feature importance
importance <- lgb.importance(model, percentage = TRUE)

# Plot feature importance
lgb.plot.importance(importance, top_n = 15, measure = "Gain")
```

### Actual vs. Predicted Values

A scatter plot comparing the actual `Fasting_Blood_Glucose` values in the test set against the model's predictions. A perfect model's points would lie on the dashed red line (where Actual = Predicted).

```{r actual_vs_predicted, fig.width=8, fig.height=6}
# Create a data frame for plotting actual vs predicted
results_df <- data.frame(Actual = y_test, Predicted = predictions)

# Create the scatter plot
ggplot(results_df, aes(x = Actual, y = Predicted)) +
  geom_point(alpha = 0.5) +
  geom_abline(intercept = 0, slope = 1, color = "red", linetype = "dashed") + # Add identity line
  labs(title = "Actual vs. Predicted Fasting Blood Glucose",
       x = "Actual Fasting Blood Glucose",
       y = "Predicted Fasting Blood Glucose") +
  theme_minimal()
```

## Conclusion

The LightGBM model was trained to predict Fasting Blood Glucose. The R-squared score of `r round(r_squared, 4)` on the test set indicates the model explains a small portion of the variance in the target variable (or performs worse than a simple mean if negative). Further steps could involve hyperparameter tuning for LightGBM or exploring other modeling techniques to improve performance. The feature importance plot shows which variables were most influential in the model's predictions.

```

